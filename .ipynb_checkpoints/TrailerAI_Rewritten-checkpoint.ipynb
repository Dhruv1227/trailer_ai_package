{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804eeb5f-4fd6-4eec-8386-8cf446e65d6f",
   "metadata": {},
   "source": [
    "# 🎬 Trailer AI — Rewritten Notebook\n",
    "End-to-end: CSV → Download (yt_dlp API) → Features → Quick Train → Evaluate → Trailer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdd067-5317-46ab-8fa7-f966baa7370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Install dependencies (pin numpy/librosa to avoid binary issues)\n",
    "!pip install -q yt-dlp opencv-python librosa==0.10.1 numpy pandas tqdm scikit-learn joblib matplotlib python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4709997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: /Users/dhruvpatel/Desktop/trailer_ai_package/data\n",
      ".env found at /Users/dhruvpatel/Desktop/trailer_ai_package/.env\n",
      "Config → WRITE_SUBS: False | cookies: None\n"
     ]
    }
   ],
   "source": [
    "# 1) Imports & working directory + .env\n",
    "import os, sys, re, json, shutil, subprocess\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import cv2, librosa, yt_dlp\n",
    "import matplotlib; matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Always write in ./data (next to this notebook)\n",
    "WORKDIR = os.path.join(os.getcwd(), \"data\")\n",
    "for d in (\"raw\", \"features\", \"models\", \"out\"):\n",
    "    os.makedirs(os.path.join(WORKDIR, d), exist_ok=True)\n",
    "print(\"Working dir:\", WORKDIR)\n",
    "\n",
    "# .env (for cookies/API etc.) — optional\n",
    "ENV_PATH = os.path.join(os.getcwd(), \".env\")\n",
    "if not os.path.exists(ENV_PATH):\n",
    "    with open(ENV_PATH, \"w\") as f:\n",
    "        f.write(\n",
    "            \"TRAILER_API_TOKEN=\\n\"\n",
    "            \"TRAILER_WRITE_SUBS=0\\n\"\n",
    "            \"TRAILER_COOKIES=\\n\"\n",
    "            \"TRAILER_SLEEP_REQUESTS=10\\n\"\n",
    "            \"TRAILER_MAX_SLEEP_INTERVAL=20\\n\"\n",
    "        )\n",
    "        print(\"Created .env template at\", ENV_PATH)\n",
    "else:\n",
    "    print(\".env found at\", ENV_PATH)\n",
    "\n",
    "load_dotenv(ENV_PATH)\n",
    "API_TOKEN = os.getenv(\"TRAILER_API_TOKEN\", \"\").strip() or None\n",
    "WRITE_SUBS = os.getenv(\"TRAILER_WRITE_SUBS\", \"0\") != \"0\"\n",
    "COOKIES_PATH = os.getenv(\"TRAILER_COOKIES\", \"\").strip() or None\n",
    "SLEEP_REQUESTS = int(os.getenv(\"TRAILER_SLEEP_REQUESTS\", \"10\") or 10)\n",
    "MAX_SLEEP_INTERVAL = int(os.getenv(\"TRAILER_MAX_SLEEP_INTERVAL\", \"20\") or 20)\n",
    "\n",
    "print(\"Config → WRITE_SUBS:\", WRITE_SUBS, \"| cookies:\", COOKIES_PATH or \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2da45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Helpers\n",
    "def basename_noext(p: str) -> str:\n",
    "    return os.path.splitext(os.path.basename(p))[0]\n",
    "\n",
    "def seconds_from_vtt_ts(ts: str) -> float:\n",
    "    parts = re.split(r\"[,:.]\", ts)\n",
    "    if len(parts) < 3:\n",
    "        return 0.0\n",
    "    h, m, s = int(parts[0]), int(parts[1]), float(parts[2])\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "def parse_vtt(vtt_path: str) -> List[Tuple[float, float, str]]:\n",
    "    if not vtt_path or not os.path.exists(vtt_path):\n",
    "        return []\n",
    "    entries = []\n",
    "    with open(vtt_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        block = []\n",
    "        for line in f:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                if block:\n",
    "                    for i, ln in enumerate(block):\n",
    "                        if \"-->\" in ln:\n",
    "                            t1, t2 = [x.strip() for x in ln.split(\"-->\")]\n",
    "                            try:\n",
    "                                s = seconds_from_vtt_ts(t1)\n",
    "                                e = seconds_from_vtt_ts(t2.split(\" \")[0])\n",
    "                                text = \" \".join(block[i+1:]).strip()\n",
    "                                if e > s:\n",
    "                                    entries.append((s, e, text))\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                            break\n",
    "                block = []\n",
    "            else:\n",
    "                block.append(line)\n",
    "        if block:\n",
    "            for i, ln in enumerate(block):\n",
    "                if \"-->\" in ln:\n",
    "                    t1, t2 = [x.strip() for x in ln.split(\"-->\")]\n",
    "                    try:\n",
    "                        s = seconds_from_vtt_ts(t1)\n",
    "                        e = seconds_from_vtt_ts(t2.split(\" \")[0])\n",
    "                        text = \" \".join(block[i+1:]).strip()\n",
    "                        if e > s:\n",
    "                            entries.append((s, e, text))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    break\n",
    "    return entries\n",
    "\n",
    "def caption_overlap(captions, start: float, end: float) -> float:\n",
    "    if not captions:\n",
    "        return 0.0\n",
    "    dur = max(1e-6, end - start)\n",
    "    covered = 0.0\n",
    "    for s, e, _ in captions:\n",
    "        inter = max(0.0, min(end, e) - max(start, s))\n",
    "        covered += inter\n",
    "    covered = min(covered, dur)\n",
    "    return covered / dur\n",
    "\n",
    "def caption_keyword_density(captions, start: float, end: float) -> float:\n",
    "    tot_words = 0.0\n",
    "    dur = max(1e-6, end - start)\n",
    "    for s, e, text in captions:\n",
    "        inter = max(0.0, min(end, e) - max(start, s))\n",
    "        if inter > 0:\n",
    "            w = len(re.findall(r\"\\w+\", text.lower()))\n",
    "            tot_words += w * (inter / (e - s + 1e-6))\n",
    "    return float(tot_words / dur)\n",
    "\n",
    "def normalize(vals: List[float]) -> np.ndarray:\n",
    "    a = np.asarray(vals, dtype=np.float32)\n",
    "    if a.size == 0:\n",
    "        return a\n",
    "    mn, mx = float(np.min(a)), float(np.max(a))\n",
    "    if mx - mn < 1e-12:\n",
    "        return np.zeros_like(a, dtype=np.float32)\n",
    "    return (a - mn) / (mx - mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ca7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Download via yt_dlp Python API (no shell)\n",
    "def download_video(url: str, raw_dir: str, write_subs: bool=False, cookies_path: Optional[str]=None,\n",
    "                   sleep_requests: Optional[int]=10, max_sleep_interval: Optional[int]=20) -> Tuple[str, Optional[str]]:\n",
    "    os.makedirs(raw_dir, exist_ok=True)\n",
    "    ydl_opts = {\n",
    "        \"outtmpl\": os.path.join(raw_dir, \"%(id)s.%(ext)s\"),\n",
    "        \"format\": \"mp4/bestvideo[ext=mp4]+bestaudio[ext=m4a]/best\",\n",
    "        \"merge_output_format\": \"mp4\",\n",
    "        \"noplaylist\": True,\n",
    "        \"quiet\": True,\n",
    "        \"retries\": 3,\n",
    "    }\n",
    "    if write_subs:\n",
    "        ydl_opts.update({\n",
    "            \"writesubtitles\": True,\n",
    "            \"writeautomaticsub\": True,\n",
    "            \"subtitleslangs\": [\"en\"],\n",
    "            \"subtitlesformat\": \"vtt\",\n",
    "        })\n",
    "    if cookies_path and os.path.exists(cookies_path):\n",
    "        ydl_opts[\"cookiefile\"] = cookies_path\n",
    "    if sleep_requests and max_sleep_interval:\n",
    "        ydl_opts[\"sleep_interval_requests\"] = sleep_requests\n",
    "        ydl_opts[\"max_sleep_interval_requests\"] = max_sleep_interval\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "        if info is None:\n",
    "            raise RuntimeError(\"yt_dlp failed to fetch info\")\n",
    "        if \"requested_downloads\" in info and info[\"requested_downloads\"]:\n",
    "            filepath = info[\"requested_downloads\"][0][\"filepath\"]\n",
    "        else:\n",
    "            vid = info.get(\"id\")\n",
    "            ext = info.get(\"ext\", \"mp4\")\n",
    "            filepath = os.path.join(raw_dir, f\"{vid}.{ext}\")\n",
    "\n",
    "    # locate VTT if present\n",
    "    vtt_path = None\n",
    "    vid = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    for cand in (os.path.join(raw_dir, f\"{vid}.en.vtt\"), os.path.join(raw_dir, f\"{vid}.vtt\")):\n",
    "        if os.path.exists(cand):\n",
    "            vtt_path = cand\n",
    "            break\n",
    "    return filepath, vtt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55750a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Feature extraction (motion, audio RMS, captions) + baseline score\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    video_id: str\n",
    "    start: float\n",
    "    end: float\n",
    "    motion: float = 0.0\n",
    "    audio: float = 0.0\n",
    "    cap_overlap: float = 0.0\n",
    "    kw_density: float = 0.0\n",
    "    score: float = 0.0\n",
    "\n",
    "def sample_video_histograms(mp4_path: str, fps_sample: float = 2.0):\n",
    "    cap = cv2.VideoCapture(mp4_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open video: {mp4_path}\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    step = max(1, int(round(fps / fps_sample)))\n",
    "    ts_list, diffs = [], []\n",
    "    prev_hist = None\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret = cap.grab()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_idx % step == 0:\n",
    "            ret, frame = cap.retrieve()\n",
    "            if not ret:\n",
    "                break\n",
    "            ts = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            h0 = cv2.calcHist([hsv], [0], None, [64], [0, 180])\n",
    "            h1 = cv2.calcHist([hsv], [1], None, [64], [0, 256])\n",
    "            h2 = cv2.calcHist([hsv], [2], None, [64], [0, 256])\n",
    "            hist = np.concatenate([h0.flatten(), h1.flatten(), h2.flatten()]).astype(np.float32)\n",
    "            hist /= (np.sum(hist) + 1e-6)\n",
    "            diffs.append(0.0 if prev_hist is None else float(np.sum(np.abs(hist - prev_hist))))\n",
    "            prev_hist = hist\n",
    "            ts_list.append(ts)\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    ts = np.array(ts_list, dtype=np.float32)\n",
    "    diffs = np.array(diffs, dtype=np.float32)\n",
    "    return ts, diffs\n",
    "\n",
    "def detect_scenes(ts: np.ndarray, diffs: np.ndarray, thresh: float = 0.55):\n",
    "    if len(ts) == 0:\n",
    "        return [(0.0, 0.0)]\n",
    "    cuts = [0]\n",
    "    for i in range(1, len(diffs)):\n",
    "        if diffs[i] > thresh:\n",
    "            cuts.append(i)\n",
    "    cuts.append(len(ts) - 1)\n",
    "    bounds = []\n",
    "    for i in range(len(cuts)-1):\n",
    "        s = float(ts[cuts[i]])\n",
    "        e = float(ts[cuts[i+1]])\n",
    "        if e > s:\n",
    "            bounds.append((s, e))\n",
    "    return bounds\n",
    "\n",
    "def make_chunks(bounds: List[Tuple[float, float]], min_len=2.0, max_len=6.0, video_id=\"vid\"):\n",
    "    chunks: List[Chunk] = []\n",
    "    for s, e in bounds:\n",
    "        cur = s\n",
    "        while cur + min_len <= e:\n",
    "            end = min(cur + max_len, e)\n",
    "            chunks.append(Chunk(video_id=video_id, start=cur, end=end))\n",
    "            cur += min_len\n",
    "    return chunks\n",
    "\n",
    "def avg_motion(diffs: np.ndarray, ts: np.ndarray, start: float, end: float) -> float:\n",
    "    mask = (ts >= start) & (ts <= end)\n",
    "    if not np.any(mask):\n",
    "        return 0.0\n",
    "    return float(np.mean(diffs[mask]))\n",
    "\n",
    "def audio_rms(mp4_path: str, start: float, end: float) -> float:\n",
    "    dur = max(0.0, end - start)\n",
    "    if dur <= 0.0:\n",
    "        return 0.0\n",
    "    try:\n",
    "        y, sr = librosa.load(mp4_path, sr=None, offset=max(0.0, start), duration=dur)\n",
    "        if y.size == 0:\n",
    "            return 0.0\n",
    "        return float(np.sqrt(np.mean(y**2)))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def compute_features_for_video(mp4_path: str, vtt_path: Optional[str], min_seg: float, max_seg: float, scene_thresh: float) -> List[Chunk]:\n",
    "    video_id = basename_noext(mp4_path)\n",
    "    captions = parse_vtt(vtt_path) if vtt_path else []\n",
    "    ts, diffs = sample_video_histograms(mp4_path, fps_sample=2.0)\n",
    "    if len(ts) == 0:\n",
    "        raise RuntimeError(\"Failed to sample frames.\")\n",
    "    bounds = detect_scenes(ts, diffs, thresh=scene_thresh) or [(0.0, float(ts[-1]))]\n",
    "    chunks = make_chunks(bounds, min_len=min_seg, max_len=max_seg, video_id=video_id)\n",
    "    for c in tqdm(chunks, desc=f\"Features {video_id}\"):\n",
    "        c.motion = avg_motion(diffs, ts, c.start, c.end)\n",
    "        c.audio = audio_rms(mp4_path, c.start, c.end)\n",
    "        c.cap_overlap = caption_overlap(captions, c.start, c.end) if captions else 0.0\n",
    "        c.kw_density = caption_keyword_density(captions, c.start, c.end) if captions else 0.0\n",
    "    # baseline score (used for pseudo-labels later)\n",
    "    m_n = normalize([c.motion for c in chunks])\n",
    "    a_n = normalize([c.audio  for c in chunks])\n",
    "    t_n = normalize([0.5*c.cap_overlap + 0.5*c.kw_density for c in chunks])\n",
    "    for i, c in enumerate(chunks):\n",
    "        c.score = float(0.4*m_n[i] + 0.4*a_n[i] + 0.2*t_n[i])\n",
    "    return chunks\n",
    "\n",
    "def greedy_select(chunks: List[Chunk], target_len: float, min_gap: float) -> List[Chunk]:\n",
    "    chosen, used_starts, total = [], [], 0.0\n",
    "    for c in sorted(chunks, key=lambda x: x.score, reverse=True):\n",
    "        if total >= target_len * 0.98:\n",
    "            break\n",
    "        if any(abs(c.start - s) < min_gap for s in used_starts):\n",
    "            continue\n",
    "        dur = c.end - c.start\n",
    "        if total + dur > target_len + 2.0:\n",
    "            continue\n",
    "        chosen.append(c)\n",
    "        used_starts.append(c.start)\n",
    "        total += dur\n",
    "    return chosen\n",
    "\n",
    "def render_trailer(mp4_path: str, chunks: List[Chunk], out_mp4: str, target_len: float, min_seg: float):\n",
    "    selected = greedy_select(chunks, target_len=target_len, min_gap=min_seg/2.0)\n",
    "    if not selected:\n",
    "        raise RuntimeError(\"No chunks selected for trailer.\")\n",
    "    tmp_dir = os.path.join(os.path.dirname(out_mp4), \"_tmp\"); os.makedirs(tmp_dir, exist_ok=True)\n",
    "    parts = []\n",
    "    for i, c in enumerate(selected):\n",
    "        part = os.path.join(tmp_dir, f\"part_{i:03d}.mp4\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\"-y\",\"-ss\",f\"{c.start:.3f}\",\"-to\",f\"{c.end:.3f}\",\n",
    "            \"-i\", mp4_path, \"-c:v\",\"libx264\",\"-preset\",\"veryfast\",\"-crf\",\"23\",\n",
    "            \"-c:a\",\"aac\",\"-b:a\",\"128k\", part\n",
    "        ]\n",
    "        try:\n",
    "            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"ffmpeg is required on PATH. Please install ffmpeg.\") from e\n",
    "        parts.append(part)\n",
    "    filelist = os.path.join(tmp_dir, \"files.txt\")\n",
    "    with open(filelist,\"w\",encoding=\"utf-8\") as f:\n",
    "        for p in parts:\n",
    "            f.write(f\"file '{os.path.abspath(p)}'\\n\")\n",
    "    os.makedirs(os.path.dirname(out_mp4), exist_ok=True)\n",
    "    subprocess.run([\"ffmpeg\",\"-y\",\"-safe\",\"0\",\"-f\",\"concat\",\"-i\",filelist,\"-c\",\"copy\", out_mp4], check=True)\n",
    "    shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "    print(\"🎬 Trailer saved:\", out_mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cbd1618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 100 video(s) from video_ids.csv\n",
      "   https://www.youtube.com/watch?v=vH1Dj4_JKVU\n",
      "   https://www.youtube.com/watch?v=Ipm6V_tOFHc\n",
      "   https://www.youtube.com/watch?v=IcxZa7HOW1o\n",
      "   https://www.youtube.com/watch?v=AJ1-WE1B2Ss\n",
      "   https://www.youtube.com/watch?v=kjsqQPMTbd4\n",
      "   https://www.youtube.com/watch?v=iaFl3AMRvEs\n",
      "   https://www.youtube.com/watch?v=mgmVOuLgFB0\n",
      "   https://www.youtube.com/watch?v=dip7rRT79gk\n",
      "   https://www.youtube.com/watch?v=43gpODUhTCQ\n",
      "   https://www.youtube.com/watch?v=FhTsFjsofrw\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "\n",
    "# Use your uploaded CSV path (update if needed)\n",
    "csv_path = os.path.join(WORKDIR, \"video_ids.csv\")  # or move it into your project folder\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"Could not find CSV at {csv_path}\")\n",
    "\n",
    "# Read file and build YouTube URLs list\n",
    "df_ids = pd.read_csv(csv_path)\n",
    "urls = []\n",
    "\n",
    "if \"url\" in df_ids.columns:\n",
    "    urls.extend(df_ids[\"url\"].dropna().astype(str).tolist())\n",
    "\n",
    "if \"video_id\" in df_ids.columns:\n",
    "    for v in df_ids[\"video_id\"].dropna().astype(str):\n",
    "        v = v.strip()\n",
    "        if v.startswith(\"http://\") or v.startswith(\"https://\"):\n",
    "            urls.append(v)\n",
    "        else:\n",
    "            urls.append(f\"https://www.youtube.com/watch?v={v}\")\n",
    "\n",
    "# Remove duplicates\n",
    "urls = list(dict.fromkeys(urls))\n",
    "\n",
    "print(f\"✅ Loaded {len(urls)} video(s) from {os.path.basename(csv_path)}\")\n",
    "for u in urls[:10]:\n",
    "    print(\"  \", u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c2b63-0514-484e-b1dc-22f204833ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Download & extract features (for ALL videos in CSV)\n",
    "min_seg, max_seg, scene_thresh = 2.0, 6.0, 0.55\n",
    "raw_dir = os.path.join(WORKDIR, \"raw\")\n",
    "features_dir = os.path.join(WORKDIR, \"features\")\n",
    "\n",
    "for url in tqdm(urls):\n",
    "    try:\n",
    "        mp4, vtt = download_video(\n",
    "            url, raw_dir,\n",
    "            write_subs=WRITE_SUBS, cookies_path=COOKIES_PATH,\n",
    "            sleep_requests=SLEEP_REQUESTS, max_sleep_interval=MAX_SLEEP_INTERVAL\n",
    "        )\n",
    "        chunks = compute_features_for_video(mp4, vtt, min_seg, max_seg, scene_thresh)\n",
    "        out_csv = os.path.join(features_dir, f\"{basename_noext(mp4)}.csv\")\n",
    "        pd.DataFrame([asdict(c) for c in chunks]).to_csv(out_csv, index=False)\n",
    "        print(\"✅ Saved features →\", out_csv)\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Error on URL:\", url, \"→\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d10ae7-1be6-499b-a7c4-72a55652e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Use the whole dataset from data/features/*.csv → auto-label → train & evaluate\n",
    "\n",
    "def load_full_dataset(features_dir: str) -> pd.DataFrame:\n",
    "    files = [os.path.join(features_dir, f) for f in os.listdir(features_dir) if f.endswith(\".csv\")]\n",
    "    if not files:\n",
    "        raise RuntimeError(\"No feature CSV files found. Run the extraction step first.\")\n",
    "    df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "    print(f\"Loaded {len(df)} total chunks from {len(files)} videos.\")\n",
    "    return df\n",
    "\n",
    "# Load all feature files\n",
    "full_df = load_full_dataset(features_dir)\n",
    "\n",
    "# Automatically generate pseudo-labels: top 30% score as highlight (label=1)\n",
    "threshold = full_df[\"score\"].quantile(0.70)\n",
    "full_df[\"label\"] = (full_df[\"score\"] >= threshold).astype(int)\n",
    "print(f\"Top 30% clips labeled as 1 (highlight) → {full_df['label'].sum()} positives / {len(full_df)} total\")\n",
    "\n",
    "# Train/test split\n",
    "feat_cols = [\"motion\", \"audio\", \"cap_overlap\", \"kw_density\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    full_df[feat_cols], full_df[\"label\"], test_size=0.2, random_state=42, stratify=full_df[\"label\"]\n",
    ")\n",
    "\n",
    "# Train quick model\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"✅ Model Evaluation (auto-labeled highlights)\")\n",
    "print(f\"Accuracy : {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall   : {rec:.3f}\")\n",
    "print(f\"F1-score : {f1:.3f}\")\n",
    "print(f\"ROC-AUC  : {auc:.3f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(WORKDIR, \"models\", \"highlight_model.pkl\")\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "joblib.dump(clf, model_path)\n",
    "print(\"Model saved →\", model_path)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(WORKDIR, \"models\", \"confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Feature importance (coefs)\n",
    "importance = pd.Series(clf.coef_[0], index=feat_cols).sort_values()\n",
    "plt.figure(figsize=(6,3.5))\n",
    "importance.plot(kind=\"barh\")\n",
    "plt.title(\"Feature Importance (LogReg Coefficients)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(WORKDIR, \"models\", \"feature_importance.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712f9ab-f92b-4941-9f1c-7ee16e6ed7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Build a trailer for one video (requires ffmpeg)\n",
    "# Pick the last downloaded mp4 (change as needed)\n",
    "mp4_list = sorted([p for p in os.listdir(raw_dir) if p.endswith(\".mp4\")])\n",
    "if not mp4_list:\n",
    "    raise RuntimeError(\"No MP4 found in raw/. Download step may have failed.\")\n",
    "mp4_path = os.path.join(raw_dir, mp4_list[-1])\n",
    "\n",
    "# Recompute features (no captions by default)\n",
    "chunks = compute_features_for_video(mp4_path, None, 2.0, 6.0, 0.55)\n",
    "\n",
    "# Score with the trained model\n",
    "Xf = np.array([[c.motion, c.audio, c.cap_overlap, c.kw_density] for c in chunks], dtype=np.float32)\n",
    "scores = clf.predict_proba(Xf)[:, 1]\n",
    "mn, mx = float(np.min(scores)), float(np.max(scores))\n",
    "norm_scores = (scores - mn) / (mx - mn + 1e-9)\n",
    "for i, c in enumerate(chunks):\n",
    "    c.score = float(norm_scores[i])\n",
    "\n",
    "# Render trailer\n",
    "out_mp4 = os.path.join(WORKDIR, \"out\", f\"{basename_noext(mp4_path)}_trailer.mp4\")\n",
    "render_trailer(mp4_path, chunks, out_mp4, target_len=20.0, min_seg=2.0)\n",
    "print(\"Trailer:\", out_mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b9cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Preference helpers (fast, 3–4 knobs) to blend with model scores\n",
    "\n",
    "def compute_pref_weights(style=\"action\", focus=\"both\"):\n",
    "    # simple weights (sum to 1) — only 3 signals: motion, audio, text\n",
    "    w_motion, w_audio, w_text = 0.4, 0.4, 0.2\n",
    "    style = (style or \"action\").strip().lower()\n",
    "    focus = (focus or \"both\").strip().lower()\n",
    "\n",
    "    if style == \"action\":\n",
    "        w_motion, w_audio, w_text = 0.55, 0.35, 0.10\n",
    "    elif style == \"emotional\":\n",
    "        w_motion, w_audio, w_text = 0.20, 0.30, 0.50\n",
    "    elif style == \"funny\":\n",
    "        w_motion, w_audio, w_text = 0.30, 0.25, 0.45\n",
    "    elif style == \"informative\":\n",
    "        w_motion, w_audio, w_text = 0.10, 0.20, 0.70\n",
    "\n",
    "    if focus == \"dialogue\":\n",
    "        w_text += 0.15\n",
    "    elif focus == \"visuals\":\n",
    "        w_motion += 0.15\n",
    "\n",
    "    total = w_motion + w_audio + w_text\n",
    "    return (w_motion/total, w_audio/total, w_text/total)\n",
    "\n",
    "def blend_model_with_prefs(chunks, model_scores, style=\"action\", focus=\"both\", blend_alpha=0.7):\n",
    "    \"\"\"\n",
    "    blend_alpha in [0,1]: 1.0 uses only model, 0.0 uses only prefs.\n",
    "    \"\"\"\n",
    "    wm, wa, wt = compute_pref_weights(style, focus)\n",
    "    m_norm = normalize([c.motion for c in chunks])\n",
    "    a_norm = normalize([c.audio for c in chunks])\n",
    "    t_norm = normalize([0.5*c.cap_overlap + 0.5*c.kw_density for c in chunks])\n",
    "    pref_scores = (wm*m_norm) + (wa*a_norm) + (wt*t_norm)\n",
    "\n",
    "    # Normalize both streams then blend\n",
    "    ms = np.asarray(model_scores, dtype=np.float32)\n",
    "    ms = (ms - ms.min()) / (ms.max() - ms.min() + 1e-9)\n",
    "    ps = (pref_scores - pref_scores.min()) / (pref_scores.max() - pref_scores.min() + 1e-9)\n",
    "\n",
    "    final = blend_alpha*ms + (1.0-blend_alpha)*ps\n",
    "    # Write scores back into chunks for downstream selection\n",
    "    for i, c in enumerate(chunks):\n",
    "        c.score = float(final[i])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4a7dbc-dd4b-4998-b2eb-9d2adab081ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a source video:\n",
      "  1) Enter a YouTube URL now\n",
      "  2) Pick by index from your CSV list (data/video_ids.csv)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 or 2 [default=2]:  1\n",
      "Paste YouTube URL:  https://www.youtube.com/watch?v=KflMqooMzF8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preferences (leave blank for defaults)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Style [action/emotional/funny/informative] (default: action):  informative\n",
      "Focus [dialogue/visuals/both] (default: both):  both\n",
      "Target trailer length in seconds (default: 20):  \n",
      "Blend α (0=prefs only, 1=model only) (default: 0.7):  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/5cf6312f/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] KflMqooMzF8: nsig extraction failed: Some formats may be missing\n",
      "         n = NGi04ZZmxNBw8aO ; player = https://www.youtube.com/s/player/5cf6312f/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] KflMqooMzF8: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] KflMqooMzF8: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features KflMqooMzF8:   0%|                             | 0/673 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/var/folders/6q/2lfjwbhs7pd_g4kpblszvhh00000gn/T/ipykernel_10378/645131136.py:83: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(mp4_path, sr=None, offset=max(0.0, start), duration=dur)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Features KflMqooMzF8:   0%|                     | 1/673 [00:01<17:55,  1.60s/it]/var/folders/6q/2lfjwbhs7pd_g4kpblszvhh00000gn/T/ipykernel_10378/645131136.py:83: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(mp4_path, sr=None, offset=max(0.0, start), duration=dur)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Features KflMqooMzF8: 100%|███████████████████| 673/673 [05:06<00:00,  2.20it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Trailer saved: /Users/dhruvpatel/Desktop/trailer_ai_package/data/out/KflMqooMzF8_trailer.mp4\n",
      "\n",
      "✅ Done. Trailer saved at: /Users/dhruvpatel/Desktop/trailer_ai_package/data/out/KflMqooMzF8_trailer.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 17.0.0 (clang-1700.3.19.1)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/8.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x8ba858280] Auto-inserting h264_mp4toannexb bitstream filter\n",
      "Input #0, concat, from '/Users/dhruvpatel/Desktop/trailer_ai_package/data/out/_tmp/files.txt':\n",
      "  Duration: N/A, start: -0.023220, bitrate: 1283 kb/s\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x960 [SAR 1:1 DAR 2:1], 1151 kb/s, 30 fps, 30 tbr, 15360 tbn, start 0.033008\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 131 kb/s, start -0.023220\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #0:1 -> #0:1 (copy)\n",
      "Output #0, mp4, to '/Users/dhruvpatel/Desktop/trailer_ai_package/data/out/KflMqooMzF8_trailer.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x960 [SAR 1:1 DAR 2:1], q=2-31, 1151 kb/s, 30 fps, 30 tbr, 15360 tbn\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 131 kb/s\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Press [q] to stop, [?] for help\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x8ba858280] Auto-inserting h264_mp4toannexb bitstream filter\n",
      "    Last message repeated 8 times\n",
      "[out#0/mp4 @ 0x8bb000fc0] video:5279KiB audio:356KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.425626%\n",
      "frame=  645 fps=0.0 q=-1.0 Lsize=    5659KiB time=00:00:21.78 bitrate=2127.7kbits/s speed= 469x elapsed=0:00:00.04    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features KflMqooMzF8:   0%|                             | 0/673 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/var/folders/6q/2lfjwbhs7pd_g4kpblszvhh00000gn/T/ipykernel_75657/645131136.py:83: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(mp4_path, sr=None, offset=max(0.0, start), duration=dur)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Features KflMqooMzF8:   0%|                     | 1/673 [00:01<14:01,  1.25s/it]/var/folders/6q/2lfjwbhs7pd_g4kpblszvhh00000gn/T/ipykernel_75657/645131136.py:83: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(mp4_path, sr=None, offset=max(0.0, start), duration=dur)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Features KflMqooMzF8: 100%|███████████████████| 673/673 [11:46<00:00,  1.05s/it]\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Trailer saved: /Users/dhruvpatel/Desktop/trailer_ai_package/data/out/KflMqooMzF8_trailer.mp4\n",
      "\n",
      "✅ Done. Trailer saved at: /Users/dhruvpatel/Desktop/trailer_ai_package/data/out/KflMqooMzF8_trailer.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 17.0.0 (clang-1700.3.19.1)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/8.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0xc3b040280] Auto-inserting h264_mp4toannexb bitstream filter\n",
      "Input #0, concat, from '/Users/dhruvpatel/Desktop/trailer_ai_package/data/out/_tmp/files.txt':\n",
      "  Duration: N/A, start: -0.023220, bitrate: 1283 kb/s\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x960 [SAR 1:1 DAR 2:1], 1151 kb/s, 30 fps, 30 tbr, 15360 tbn, start 0.033008\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 131 kb/s, start -0.023220\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #0:1 -> #0:1 (copy)\n",
      "Output #0, mp4, to '/Users/dhruvpatel/Desktop/trailer_ai_package/data/out/KflMqooMzF8_trailer.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x960 [SAR 1:1 DAR 2:1], q=2-31, 1151 kb/s, 30 fps, 30 tbr, 15360 tbn\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 131 kb/s\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Press [q] to stop, [?] for help\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0xc3b040280] Auto-inserting h264_mp4toannexb bitstream filter\n",
      "    Last message repeated 8 times\n",
      "[out#0/mp4 @ 0xc3b035740] video:5279KiB audio:356KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.425626%\n",
      "frame=  645 fps=0.0 q=-1.0 Lsize=    5659KiB time=00:00:21.78 bitrate=2127.7kbits/s speed= 314x elapsed=0:00:00.06    \n"
     ]
    }
   ],
   "source": [
    "# B) Take user input → build trailer with trained model + preferences\n",
    "# Paste this AFTER training so highlight_model.pkl exists.\n",
    "\n",
    "# Load model if needed\n",
    "model_path = os.path.join(WORKDIR, \"models\", \"highlight_model.pkl\")\n",
    "if \"clf\" not in globals():\n",
    "    if not os.path.exists(model_path):\n",
    "        raise RuntimeError(\"Trained model not found. Run the training cell first.\")\n",
    "    clf = joblib.load(model_path)\n",
    "\n",
    "# 1) Let user choose the source video\n",
    "print(\"Choose a source video:\")\n",
    "print(\"  1) Enter a YouTube URL now\")\n",
    "print(\"  2) Pick by index from your CSV list (data/video_ids.csv)\")\n",
    "choice = input(\"Enter 1 or 2 [default=2]: \").strip() or \"2\"\n",
    "\n",
    "if choice == \"1\":\n",
    "    url = input(\"Paste YouTube URL: \").strip()\n",
    "    if not (url.startswith(\"http://\") or url.startswith(\"https://\")):\n",
    "        raise ValueError(\"Please provide a full YouTube URL.\")\n",
    "else:\n",
    "    # Read from your CSV in WORKDIR\n",
    "    csv_path = os.path.join(WORKDIR, \"video_ids.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        # fallback: try to copy if you used /mnt/data upload earlier\n",
    "        import shutil\n",
    "        src = \"/mnt/data/video_ids.csv\"\n",
    "        if os.path.exists(src):\n",
    "            shutil.copy(src, csv_path)\n",
    "    df_pick = pd.read_csv(csv_path)\n",
    "    url_list = []\n",
    "    if \"url\" in df_pick.columns:\n",
    "        url_list += df_pick[\"url\"].dropna().astype(str).str.strip().tolist()\n",
    "    if \"video_id\" in df_pick.columns:\n",
    "        for v in df_pick[\"video_id\"].dropna().astype(str).str.strip():\n",
    "            url_list.append(v if v.startswith(\"http\") else f\"https://www.youtube.com/watch?v={v}\")\n",
    "    # dedupe\n",
    "    seen = set(); url_list = [u for u in url_list if not (u in seen or seen.add(u))]\n",
    "    if not url_list:\n",
    "        raise RuntimeError(\"No rows found in CSV. Add at least one video_id or url.\")\n",
    "\n",
    "    print(f\"\\nFound {len(url_list)} entries:\")\n",
    "    for i, u in enumerate(url_list[:20]):  # show first 20\n",
    "        print(f\"  [{i}] {u}\")\n",
    "    idx = input(f\"Pick an index [0..{len(url_list)-1}, default=0]: \").strip() or \"0\"\n",
    "    idx = int(idx)\n",
    "    if not (0 <= idx < len(url_list)):\n",
    "        raise ValueError(\"Index out of range.\")\n",
    "    url = url_list[idx]\n",
    "\n",
    "print(\"\\nPreferences (leave blank for defaults)\")\n",
    "style = (input(\"Style [action/emotional/funny/informative] (default: action): \").strip() or \"action\")\n",
    "focus = (input(\"Focus [dialogue/visuals/both] (default: both): \").strip() or \"both\")\n",
    "try:\n",
    "    target_len = float(input(\"Target trailer length in seconds (default: 20): \").strip() or 20.0)\n",
    "except Exception:\n",
    "    target_len = 20.0\n",
    "try:\n",
    "    alpha = float(input(\"Blend α (0=prefs only, 1=model only) (default: 0.7): \").strip() or 0.7)\n",
    "    alpha = min(max(alpha, 0.0), 1.0)\n",
    "except Exception:\n",
    "    alpha = 0.7\n",
    "\n",
    "# 2) Download the chosen video (no subtitles by default to avoid 429)\n",
    "raw_dir = os.path.join(WORKDIR, \"raw\")\n",
    "mp4_path, vtt_path = download_video(\n",
    "    url, raw_dir,\n",
    "    write_subs=WRITE_SUBS,\n",
    "    cookies_path=COOKIES_PATH,\n",
    "    sleep_requests=SLEEP_REQUESTS,\n",
    "    max_sleep_interval=MAX_SLEEP_INTERVAL\n",
    ")\n",
    "\n",
    "# 3) Extract features\n",
    "chunks = compute_features_for_video(mp4_path, vtt_path if WRITE_SUBS else None, min_seg=2.0, max_seg=6.0, scene_thresh=0.55)\n",
    "\n",
    "# 4) Score with trained model and blend with preferences\n",
    "Xf = np.array([[c.motion, c.audio, c.cap_overlap, c.kw_density] for c in chunks], dtype=np.float32)\n",
    "proba = clf.predict_proba(Xf)[:, 1]\n",
    "_ = blend_model_with_prefs(chunks, proba, style=style, focus=focus, blend_alpha=alpha)\n",
    "\n",
    "# 5) Render the trailer\n",
    "out_mp4 = os.path.join(WORKDIR, \"out\", f\"{basename_noext(mp4_path)}_trailer.mp4\")\n",
    "render_trailer(mp4_path, chunks, out_mp4, target_len=target_len, min_seg=2.0)\n",
    "print(\"\\n✅ Done. Trailer saved at:\", out_mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cde3ae-bada-490d-a816-0ec458f1b4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
